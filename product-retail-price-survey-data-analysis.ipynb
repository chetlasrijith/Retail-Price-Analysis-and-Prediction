{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11390664,"sourceType":"datasetVersion","datasetId":7035203}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n## Dataset Overview\n\nThis dataset contains **retail price survey data** for various products collected across different countries and time periods. It includes pricing details both before and after tax, tax applicability, product categorization, and geographic information. The dataset is rich enough for **time-series analysis, price classification, tax impact analysis**, and **geospatial price comparisons**.\n\n---\n\n###  Feature Descriptions\n\n| Feature Name         | Description                                                                 |\n|----------------------|-----------------------------------------------------------------------------|\n| **Year**             | The year in which the price data was recorded (e.g., 2022)                  |\n| **Month**            | The name of the month of the price survey (e.g., January, February)         |\n| **GEO**              | Geographical location or country where the product data was collected       |\n| **Product Category** | The main category of the product (e.g., Food, Fuel, Healthcare)             |\n| **Products**         | Specific name or type of the product surveyed                               |\n| **VALUE**            | Retail price of the product before tax (numeric)                            |\n| **Taxable**          | Indicates whether the product is subject to tax (Yes/No or similar values)  |\n| **Total tax rate**   | The tax rate applied to the product, expressed as a percentage              |\n| **Value after tax**  | Final product price after tax has been applied                              |\n| **Essential**        | Denotes whether the product is categorized as essential (Yes/No)            |\n| **COORDINATE**       | A numerical value possibly representing location or latitude/longitude      |\n| **UOM**              | Unit of Measure for the product pricing (e.g., per kg, per liter)           |\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# 1. Importing Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LinearRegression\nimport geopandas as gpd\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:07.742001Z","iopub.execute_input":"2025-04-11T09:54:07.742466Z","iopub.status.idle":"2025-04-11T09:54:11.131071Z","shell.execute_reply.started":"2025-04-11T09:54:07.742431Z","shell.execute_reply":"2025-04-11T09:54:11.130015Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Loading & Inspecting the Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/product-retail-price-survey-2017-2025/Retail_Prices_of _Products.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.133017Z","iopub.execute_input":"2025-04-11T09:54:11.133649Z","iopub.status.idle":"2025-04-11T09:54:11.395443Z","shell.execute_reply.started":"2025-04-11T09:54:11.13362Z","shell.execute_reply":"2025-04-11T09:54:11.394438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.396419Z","iopub.execute_input":"2025-04-11T09:54:11.396738Z","iopub.status.idle":"2025-04-11T09:54:11.417976Z","shell.execute_reply.started":"2025-04-11T09:54:11.396714Z","shell.execute_reply":"2025-04-11T09:54:11.416946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.41887Z","iopub.execute_input":"2025-04-11T09:54:11.419898Z","iopub.status.idle":"2025-04-11T09:54:11.483916Z","shell.execute_reply.started":"2025-04-11T09:54:11.419869Z","shell.execute_reply":"2025-04-11T09:54:11.4828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.48499Z","iopub.execute_input":"2025-04-11T09:54:11.485264Z","iopub.status.idle":"2025-04-11T09:54:11.530131Z","shell.execute_reply.started":"2025-04-11T09:54:11.485242Z","shell.execute_reply":"2025-04-11T09:54:11.528961Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Cleaning & Preparing","metadata":{}},{"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Month'] + ' ' + df['Year'].astype(str))\ndf['Taxable'] = df['Taxable'].astype('category')\ndf['Essential'] = df['Essential'].astype('category')\ndf['Product Category'] = df['Product Category'].astype('category')\ndf['GEO'] = df['GEO'].astype('category')\ndf = df.dropna(subset=['VALUE'])\ndf['Price_Level'] = pd.qcut(df['VALUE'], q=3, labels=['Low', 'Medium', 'High'])\ndf['Month_num'] = df['Date'].dt.month\ndf['Year_num'] = df['Date'].dt.year","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.531113Z","iopub.execute_input":"2025-04-11T09:54:11.531387Z","iopub.status.idle":"2025-04-11T09:54:11.704815Z","shell.execute_reply.started":"2025-04-11T09:54:11.531361Z","shell.execute_reply":"2025-04-11T09:54:11.703955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. EDA ","metadata":{}},{"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nplt.figure(figsize=(12,6))\nsns.boxplot(x='Essential', y='VALUE', data=df)\nplt.title('Price Distribution by Essential Items')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.705871Z","iopub.execute_input":"2025-04-11T09:54:11.706176Z","iopub.status.idle":"2025-04-11T09:54:11.952863Z","shell.execute_reply.started":"2025-04-11T09:54:11.706152Z","shell.execute_reply":"2025-04-11T09:54:11.951855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.barplot(data=df, x='Product Category', y='VALUE', ci=None)\nplt.xticks(rotation=90)\nplt.title('Average Price by Product Category')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:11.955763Z","iopub.execute_input":"2025-04-11T09:54:11.956092Z","iopub.status.idle":"2025-04-11T09:54:12.324361Z","shell.execute_reply.started":"2025-04-11T09:54:11.956064Z","shell.execute_reply":"2025-04-11T09:54:12.323315Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Price Trend Analysis (Time Series)","metadata":{}},{"cell_type":"code","source":"avg_monthly = df.groupby('Date')['VALUE'].mean().reset_index()\nplt.figure(figsize=(14,6))\nsns.lineplot(data=avg_monthly, x='Date', y='VALUE')\nplt.title('Average Price Over Time')\nplt.xlabel('Date')\nplt.ylabel('Average Price')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:12.325425Z","iopub.execute_input":"2025-04-11T09:54:12.325715Z","iopub.status.idle":"2025-04-11T09:54:12.793463Z","shell.execute_reply.started":"2025-04-11T09:54:12.325692Z","shell.execute_reply":"2025-04-11T09:54:12.79228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Category-wise Price Comparison","metadata":{}},{"cell_type":"code","source":"cat_month = df.groupby(['Date','Product Category'])['VALUE'].mean().reset_index()\nplt.figure(figsize=(16,8))\nsns.lineplot(data=cat_month, x='Date', y='VALUE', hue='Product Category')\nplt.title('Category-wise Price Trend')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:12.794646Z","iopub.execute_input":"2025-04-11T09:54:12.794958Z","iopub.status.idle":"2025-04-11T09:54:13.525213Z","shell.execute_reply.started":"2025-04-11T09:54:12.794904Z","shell.execute_reply":"2025-04-11T09:54:13.524138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Anomaly Detection","metadata":{}},{"cell_type":"code","source":"iso = IsolationForest(contamination=0.01)\ndf['anomaly'] = iso.fit_predict(df[['VALUE']])\nanomalies = df[df['anomaly'] == -1]\nplt.figure(figsize=(14,6))\nsns.scatterplot(data=df, x='Date', y='VALUE', label='Normal')\nsns.scatterplot(data=anomalies, x='Date', y='VALUE', color='r', label='Anomaly')\nplt.title('Price Anomaly Detection')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:13.526326Z","iopub.execute_input":"2025-04-11T09:54:13.526675Z","iopub.status.idle":"2025-04-11T09:54:21.236808Z","shell.execute_reply.started":"2025-04-11T09:54:13.526648Z","shell.execute_reply":"2025-04-11T09:54:21.235697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Regression Modeling","metadata":{}},{"cell_type":"code","source":"reg_data = df[['VALUE', 'Taxable', 'Essential', 'Product Category', 'GEO', 'Month_num', 'Year_num']].copy()\nreg_data = pd.get_dummies(reg_data, drop_first=True)\nX_reg = reg_data.drop(columns=['VALUE'])\ny_reg = reg_data['VALUE']\nX_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\nreg_model = LinearRegression()\nreg_model.fit(X_train_r, y_train_r)\ny_pred_r = reg_model.predict(X_test_r)\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(\"Linear Regression RMSE:\", mean_squared_error(y_test_r, y_pred_r, squared=False))\nprint(\"Linear Regression R2 Score:\", r2_score(y_test_r, y_pred_r))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:54:21.237794Z","iopub.execute_input":"2025-04-11T09:54:21.238154Z","iopub.status.idle":"2025-04-11T09:54:21.480015Z","shell.execute_reply.started":"2025-04-11T09:54:21.238123Z","shell.execute_reply":"2025-04-11T09:54:21.478918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Classification Modeling","metadata":{}},{"cell_type":"code","source":"\n\nle = LabelEncoder()\ny = le.fit_transform(df['Price_Level'])  # Converts 'Low', 'Medium', 'High' to 0, 1, 2\n\nX = df.drop(columns=['VALUE', 'Value after tax', 'Total tax rate', 'Date', 'Products', 'Price_Level', 'Month', 'Year'])\ny = df['Price_Level']\nX_encoded = pd.get_dummies(X, drop_first=True)\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodels = [\n    LogisticRegression(max_iter=1000),\n    RandomForestClassifier(n_estimators=100, random_state=42),\n    GradientBoostingClassifier(),\n    LGBMClassifier(),\n\n]\n\nfor model in models:\n    model.fit(X_train_scaled, y_train)\n    preds = model.predict(X_test_scaled)\n    print(f\"\\nModel: {model.__class__.__name__}\")\n    print(\"Accuracy:\", accuracy_score(y_test, preds))\n    print(\"Classification Report:\\n\", classification_report(y_test, preds))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T09:56:21.647503Z","iopub.execute_input":"2025-04-11T09:56:21.648123Z","iopub.status.idle":"2025-04-11T09:57:28.187907Z","shell.execute_reply.started":"2025-04-11T09:56:21.648085Z","shell.execute_reply":"2025-04-11T09:57:28.186671Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n##  **Project Summary**\n\nThis comprehensive data science project focuses on understanding retail product pricing behavior using a real-world dataset. The workflow is designed to incorporate key stages of data analysis, visualization, anomaly detection, and machine learning. Here's a summary of each component:\n\n---\n\n####  1. **Data Import and Inspection**\n- The dataset was loaded and inspected for structure, data types, and null values.\n- Key columns include: `VALUE` (price), `Product Category`, `GEO`, `Taxable`, `Essential`, `Month`, `Year`.\n\n---\n\n####  2. **Data Cleaning & Feature Engineering**\n- Combined `Month` and `Year` into a single datetime column.\n- Removed nulls in price (`VALUE`) and categorized prices into Low/Medium/High tiers.\n- Encoded categorical features and extracted numerical month/year for modeling.\n\n---\n\n####  3. **Exploratory Data Analysis (EDA)**\n- Boxplots and barplots showed how prices differ based on item essentiality and product category.\n- Key findings:\n  - Essential items typically have lower and more stable prices.\n  - Some categories (e.g., Meat, Dairy) consistently show higher average prices.\n\n---\n\n####  4. **Time Series Analysis**\n- Average prices were plotted over time to observe trends.\n- Result: Prices increased steadily, especially post-pandemic years, indicating possible inflationary effects.\n\n---\n\n####  5. **Category-wise Price Trends**\n- Time-based line plots by product category illustrated seasonal or cyclical changes in certain items (e.g., fruits/vegetables).\n\n---\n\n####  6. **Anomaly Detection**\n- Used Isolation Forest to identify pricing anomalies.\n- Detected spikes and dips in specific time windows, potentially indicating supply chain disruptions or market irregularities.\n\n---\n\n####  7. **Regression Modeling**\n- Applied Linear Regression to predict actual price (`VALUE`) using engineered features.\n- RMSE and RÂ² scores showed moderate accuracy â€” highlighting complexity in pricing influenced by many external factors.\n\n---\n\n####  8. **Classification Modeling (Price Tier Prediction)**\n- Transformed price into categorical levels (`Low`, `Medium`, `High`) and tested 6 ML models:\n  - **Logistic Regression**\n  - **Random Forest**\n  - **Gradient Boosting**\n\n---\n\n\n\n# Thank you for taking the time to review my work. I would be very happy if you could upvote! ðŸ˜Š","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}